{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "\n",
    "## Scott Scheraga  7/24/2020\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker\n",
      "Worker\n",
      "Worker\n",
      "Worker\n",
      "Worker\n",
      "Worker\n",
      "Worker\n",
      "Worker\n",
      "Worker\n",
      "Worker\n",
      "Worker\n",
      "Worker\n",
      "Worker\n",
      "Worker\n",
      "WorkerWorker\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Worker\n",
      "Worker\n",
      "Worker\n",
      "Worker\n"
     ]
    }
   ],
   "source": [
    "#Code is largely built off of https://keras.io/examples/rl/ddpg_pendulum/\n",
    "#HER code is inspired by pybullet code at https://github.com/buntyke/her/blob/master/ddpg_her.py\n",
    "\n",
    "#from gym.envs.registration import registry, make, spec, register\n",
    "#python -m pybullet_envs.examples.enjoy_TF_HalfCheetahBulletEnv_v0_2017may\n",
    "\n",
    "\n",
    "import gym\n",
    "import pybullet_envs\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gym import wrappers\n",
    "from IPython import display\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "import math \n",
    "\n",
    "import os\n",
    "import gym\n",
    "from gym import utils\n",
    "from gym.envs import mujoco\n",
    "import mujoco_py\n",
    "import cv2\n",
    "from gym.envs.robotics import fetch_env\n",
    "import threading\n",
    "threading.activeCount()\n",
    "\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "def worker():\n",
    "    \"\"\"worker function\"\"\"\n",
    "    print ('Worker')\n",
    "    return\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    jobs = []\n",
    "    for i in range(20):\n",
    "        p = multiprocessing.Process(target=worker)\n",
    "        jobs.append(p)\n",
    "        p.start()\n",
    "        \n",
    "threading.activeCount()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs space\n",
      "Dict(achieved_goal:Box(3,), desired_goal:Box(3,), observation:Box(10,))\n",
      "OrderedDict([('achieved_goal', array([-0.7999555 , -0.64163536, -0.6665717 ], dtype=float32)), ('desired_goal', array([-0.21544625,  0.11928447,  0.10601705], dtype=float32)), ('observation', array([ 1.013466  ,  1.4645615 , -0.14174716,  0.995008  ,  0.37054268,\n",
      "        0.4568515 , -1.3315579 , -1.8319721 ,  0.144044  , -1.2683587 ],\n",
      "      dtype=float32))])\n",
      " \n",
      " \n",
      "Action space\n",
      "Box(4,)\n",
      "[ 0.5776261  -0.33095253  0.87638354 -0.9947676 ]\n",
      "numgoals= 3\n",
      " \n",
      " \n",
      "Size of State Space ->  10\n",
      "Size of Action Space ->  4\n",
      "Max Value of Action ->  1.0\n",
      "Min Value of Action ->  -1.0\n",
      " \n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#env = gym.make('Pendulum-v0')\n",
    "#env = gym.make('CartPole-v1')\n",
    "#env = gym.make('HalfCheetahBulletEnv-v0')\n",
    "\n",
    "\n",
    "#env = gym.make('FetchPickAndPlace-v1')\n",
    "\n",
    "\n",
    "#env = gym.make('FetchPush-v1')\n",
    "env = gym.make('FetchReach-v1')\n",
    "\n",
    "#env = gym.make('Reacher-v2')\n",
    "\n",
    "#Env information at:\n",
    "# https://medium.com/@Amritpal001/intro-to-robotics-in-openai-fetch-reach-env-automating-robotics-with-reinforcement-learning-part-2b7452f3a5e9\n",
    "\n",
    "print(\"Obs space\")\n",
    "print(env.observation_space) #.shape\n",
    "print(env.observation_space.sample())\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\"Action space\")\n",
    "print(env.action_space) #.shape\n",
    "print(env.action_space.sample())\n",
    "num_states = env.observation_space['observation'].shape[0]\n",
    "num_goals = env.observation_space['achieved_goal'].shape[0]\n",
    "print(\"numgoals=\",num_goals)\n",
    "\n",
    "#num_states = env.observation_space.shape[0]\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "#num_states=25\n",
    "print(\"Size of State Space ->  {}\".format(num_states))\n",
    "num_actions = env.action_space.shape[0]\n",
    "print(\"Size of Action Space ->  {}\".format(num_actions))\n",
    "\n",
    "upper_bound = env.action_space.high[0]\n",
    "lower_bound = env.action_space.low[0]\n",
    "\n",
    "print(\"Max Value of Action ->  {}\".format(upper_bound))\n",
    "print(\"Min Value of Action ->  {}\".format(lower_bound))\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "#print(\"initial_state\")\n",
    "#print(env.initial_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom gym import utils\\nfrom gym.envs.robotics import fetch_env\\n\\n\\n# Ensure we get the path separator correct on windows\\nMODEL_XML_PATH = os.path.join('fetch', 'reach.xml')\\n\\n\\nclass FetchReachEnv(fetch_env.FetchEnv, utils.EzPickle):\\n    def __init__(self, reward_type='sparse'):\\n        initial_qpos = {\\n            'robot0:slide0': 0.4049,\\n            'robot0:slide1': 0.48,\\n            'robot0:slide2': 0.0,\\n        }\\n        fetch_env.FetchEnv.__init__(\\n            self, MODEL_XML_PATH, has_object=False, block_gripper=True, n_substeps=20,\\n            gripper_extra_height=0.2, target_in_the_air=True, target_offset=0.0,\\n            obj_range=0.15, target_range=0.15, distance_threshold=0.05,\\n            initial_qpos=initial_qpos, reward_type=reward_type)\\n        utils.EzPickle.__init__(self)\\n        \\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fetch reach definition\n",
    "#https://github.com/openai/gym/blob/master/gym/envs/robotics/fetch/reach.py\n",
    "\"\"\"\n",
    "from gym import utils\n",
    "from gym.envs.robotics import fetch_env\n",
    "\n",
    "\n",
    "# Ensure we get the path separator correct on windows\n",
    "MODEL_XML_PATH = os.path.join('fetch', 'reach.xml')\n",
    "\n",
    "\n",
    "class FetchReachEnv(fetch_env.FetchEnv, utils.EzPickle):\n",
    "    def __init__(self, reward_type='sparse'):\n",
    "        initial_qpos = {\n",
    "            'robot0:slide0': 0.4049,\n",
    "            'robot0:slide1': 0.48,\n",
    "            'robot0:slide2': 0.0,\n",
    "        }\n",
    "        fetch_env.FetchEnv.__init__(\n",
    "            self, MODEL_XML_PATH, has_object=False, block_gripper=True, n_substeps=20,\n",
    "            gripper_extra_height=0.2, target_in_the_air=True, target_offset=0.0,\n",
    "            obj_range=0.15, target_range=0.15, distance_threshold=0.05,\n",
    "            initial_qpos=initial_qpos, reward_type=reward_type)\n",
    "        utils.EzPickle.__init__(self)\n",
    "        \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUActionNoise:\n",
    "    def __init__(self, mean, std_deviation, theta=0.15, dt=1e-2, x_initial=None):\n",
    "        self.theta = theta\n",
    "        self.mean = mean\n",
    "        self.std_dev = std_deviation\n",
    "        self.dt = dt\n",
    "        self.x_initial = x_initial\n",
    "        self.reset()\n",
    "\n",
    "    def __call__(self):\n",
    "        # Formula taken from https://www.wikipedia.org/wiki/Ornstein-Uhlenbeck_process.\n",
    "        x = (\n",
    "            self.x_prev\n",
    "            + self.theta * (self.mean - self.x_prev) * self.dt\n",
    "            + self.std_dev * np.sqrt(self.dt) * np.random.normal(size=self.mean.shape)\n",
    "        )\n",
    "        # Store x into x_prev\n",
    "        # Makes next noise dependent on current one\n",
    "        self.x_prev = x\n",
    "        return x\n",
    "\n",
    "    def reset(self):\n",
    "        if self.x_initial is not None:\n",
    "            self.x_prev = self.x_initial\n",
    "        else:\n",
    "            self.x_prev = np.zeros_like(self.mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buffer:\n",
    "    def __init__(self, buffer_capacity=100000, batch_size=256):\n",
    "    \n",
    "        # Number of \"experiences\" to store at max\n",
    "        self.buffer_capacity = buffer_capacity\n",
    "        # Num of tuples to train on.\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Its tells us num of times record() was called.\n",
    "        self.buffer_counter = 0\n",
    "\n",
    "        # Instead of list of tuples as the exp.replay concept go\n",
    "        # We use different np.arrays for each tuple element\n",
    "        self.state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        self.action_buffer = np.zeros((self.buffer_capacity, num_actions))\n",
    "        self.reward_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.next_state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        self.achieved_goal_buffer = np.zeros((self.buffer_capacity, num_goals))\n",
    "        self.goal_buffer = np.zeros((self.buffer_capacity, num_goals)) \n",
    "\n",
    "    # Takes (s,a,r,s') obervation tuple as input\n",
    "    def record(self, obs_tuple):\n",
    "        # Set index to zero if buffer_capacity is exceeded,\n",
    "        # replacing old records\n",
    "        index = self.buffer_counter % self.buffer_capacity\n",
    "\n",
    "        self.state_buffer[index] = obs_tuple[0]\n",
    "        self.action_buffer[index] = obs_tuple[1]\n",
    "        self.reward_buffer[index] = obs_tuple[2]\n",
    "        self.next_state_buffer[index] = obs_tuple[3]\n",
    "        self.achieved_goal_buffer[index] = obs_tuple[4]\n",
    "        self.goal_buffer[index] = obs_tuple[5]\n",
    "        \n",
    "        \n",
    "        if self.buffer_counter<self.buffer_capacity:\n",
    "            self.buffer_counter += 1\n",
    "            \n",
    "\n",
    "    # We compute the loss and update parameters\n",
    "    def learn(self):\n",
    "        # Get sampling range\n",
    "        record_range = min(self.buffer_counter, self.buffer_capacity)\n",
    "        # Randomly sample indices\n",
    "        batch_indices = np.random.choice(record_range, self.batch_size)\n",
    "\n",
    "        # Convert to tensors\n",
    "        state_batch = tf.convert_to_tensor(self.state_buffer[batch_indices])\n",
    "        action_batch = tf.convert_to_tensor(self.action_buffer[batch_indices])\n",
    "        reward_batch = tf.convert_to_tensor(self.reward_buffer[batch_indices])\n",
    "        reward_batch = tf.cast(reward_batch, dtype=tf.float32)\n",
    "        next_state_batch = tf.convert_to_tensor(self.next_state_buffer[batch_indices])\n",
    "        achieved_goal_batch = tf.convert_to_tensor(self.achieved_goal_buffer[batch_indices])\n",
    "        goal_batch = tf.convert_to_tensor(self.goal_buffer[batch_indices])\n",
    "\n",
    "        # Training and updating Actor & Critic networks.\n",
    "        # See Pseudo Code.\n",
    "        with tf.GradientTape() as tape:\n",
    "            target_actions = target_actor(next_state_batch)\n",
    "            y = reward_batch + gamma * target_critic([next_state_batch, target_actions])\n",
    "            critic_value = critic_model([state_batch, action_batch])\n",
    "            critic_loss = tf.math.reduce_mean(tf.math.square(y - critic_value))\n",
    "\n",
    "        critic_grad = tape.gradient(critic_loss, critic_model.trainable_variables)\n",
    "        critic_optimizer.apply_gradients(\n",
    "            zip(critic_grad, critic_model.trainable_variables)\n",
    "        )\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            actions = actor_model(state_batch)\n",
    "            critic_value = critic_model([state_batch, actions])\n",
    "            # Used `-value` as we want to maximize the value given\n",
    "            # by the critic for our actions\n",
    "            actor_loss = -tf.math.reduce_mean(critic_value)\n",
    "\n",
    "        actor_grad = tape.gradient(actor_loss, actor_model.trainable_variables)\n",
    "        actor_optimizer.apply_gradients(\n",
    "            zip(actor_grad, actor_model.trainable_variables)\n",
    "        )\n",
    "\n",
    "\n",
    "# This update target parameters slowly\n",
    "# Based on rate `tau`, which is much less than one.\n",
    "def update_target(tau):\n",
    "    new_weights = []\n",
    "    target_variables = target_critic.weights\n",
    "    for i, variable in enumerate(critic_model.weights):\n",
    "        new_weights.append(variable * tau + target_variables[i] * (1 - tau))\n",
    "\n",
    "    target_critic.set_weights(new_weights)\n",
    "\n",
    "    new_weights = []\n",
    "    target_variables = target_actor.weights\n",
    "    for i, variable in enumerate(actor_model.weights):\n",
    "        new_weights.append(variable * tau + target_variables[i] * (1 - tau))\n",
    "\n",
    "    target_actor.set_weights(new_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "layersize=400\n",
    "\n",
    "def get_actor():  #makes actor network\n",
    "    # Initialize weights between -3e-3 and 3-e3\n",
    "    last_init = tf.random_uniform_initializer(minval=-0.003, maxval=0.003)\n",
    "\n",
    "    inputs = layers.Input(shape=(num_states,))\n",
    "    out = layers.Dense(layersize, activation=\"relu\")(inputs)\n",
    "    out = layers.BatchNormalization()(out)\n",
    "    out = layers.Dense(layersize, activation=\"relu\")(out)\n",
    "    out = layers.BatchNormalization()(out)\n",
    "    outputs = layers.Dense(num_actions, activation=\"tanh\", kernel_initializer=last_init)(out)\n",
    "    # Our upper bound is 2.0 for Pendulum.\n",
    "    outputs = outputs * upper_bound\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model\n",
    " \n",
    "def get_critic():\n",
    "    # State as input\n",
    "    state_input = layers.Input(shape=(num_states))\n",
    "    #state_out = layers.Dense(16, activation=\"relu\")(state_input)#Changed from 16 to 512 in V5\n",
    "    #state_out = layers.BatchNormalization()(state_out)\n",
    "    #state_out = layers.Dense(32, activation=\"relu\")(state_out)#Changed from 32 to 512 in V5\n",
    "    #state_out = layers.BatchNormalization()(state_out) \n",
    "\n",
    "    # Action as input\n",
    "    action_input = layers.Input(shape=(num_actions))\n",
    "    #action_out = layers.Dense(32, activation=\"relu\")(action_input)  #Changed from 32 to 512 in V5\n",
    "    #action_out = layers.BatchNormalization()(action_out)#Changed from 32 to 512 in V5\n",
    "\n",
    " \n",
    "    # Both are passed through seperate layer before concatenating\n",
    "    #concat = layers.Concatenate()([state_out, action_out])\n",
    "    concat = layers.Concatenate()([state_input, action_input])\n",
    "\n",
    "    out = layers.Dense(layersize, activation=\"relu\")(concat)\n",
    "    out = layers.BatchNormalization()(out)\n",
    "    out = layers.Dense(layersize, activation=\"relu\")(out)\n",
    "    out = layers.BatchNormalization()(out)\n",
    "    outputs = layers.Dense(1)(out)\n",
    "\n",
    "    # Outputs single value for give state-action\n",
    "    model = tf.keras.Model([state_input, action_input], outputs)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(state, noise_object):\n",
    "    sampled_actions = tf.squeeze(actor_model(state))\n",
    "    noise = noise_object()\n",
    "    # Adding noise to action\n",
    "    sampled_actions = sampled_actions.numpy() + noise\n",
    "\n",
    "    # We make sure action is within bounds\n",
    "    legal_action = np.clip(sampled_actions, lower_bound, upper_bound)\n",
    "\n",
    "    return np.squeeze(legal_action)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "std_dev = 0.2\n",
    "ou_noise = OUActionNoise(mean=np.zeros(1), std_deviation=float(std_dev) * np.ones(1))\n",
    "\n",
    "#actor_model = get_actor()\n",
    "#critic_model = get_critic()\n",
    "\n",
    "#target_actor = get_actor()\n",
    "#target_critic = get_critic()\n",
    "#print(actor_model.summary() )\n",
    "#critic_model.summary() \n",
    "\n",
    "# Making the weights equal initially\n",
    "\n",
    "\n",
    "# Learning rate for actor-critic models\n",
    "critic_lr = 0.001  #originally .002\n",
    "actor_lr = 0.001  #originally .001\n",
    "\n",
    "\n",
    "#total_episodes = 100\n",
    "# Discount factor for future rewards\n",
    "gamma = 0.99\n",
    "# Used to update target networks\n",
    "tau = 0.01\n",
    "\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time is:  2020-07-24 13:30:05.780278\n",
      "Episode * 0 *  HER Reward: -61.0 *  Ep Reward: -50.0 *  Accuracy: 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b6e9b4463dac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_prev_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mou_noise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# Recieve state and reward from environment.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;31m#desired_goal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_episode_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/gym/envs/robotics/robot_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# To store reward history of each episode\n",
    "\n",
    "\n",
    "ep_reward_list = []\n",
    "buffersize=100000\n",
    "buffer = Buffer(buffersize, 128)  \n",
    "actor_model = get_actor()\n",
    "critic_model = get_critic()\n",
    "\n",
    "\n",
    "target_actor = get_actor()\n",
    "target_critic = get_critic()\n",
    "target_actor.set_weights(actor_model.get_weights())\n",
    "target_critic.set_weights(critic_model.get_weights())\n",
    "critic_optimizer = tf.keras.optimizers.Adam(critic_lr)\n",
    "actor_optimizer = tf.keras.optimizers.Adam(actor_lr)\n",
    "\n",
    "\"\"\"\"\"\"\n",
    "\n",
    "HER_active=True\n",
    "K=4 #K is the ratio of HER buffer length to the regular buffer length\n",
    "\n",
    "\"\"\"\n",
    "actor_model.load_weights(\"chet_actor100v8.h5\")\n",
    "critic_model.load_weights(\"chet_critic100v8.h5\")\n",
    "\n",
    "target_actor.load_weights(\"chet_target_actor100v8.h5\")\n",
    "target_critic.load_weights(\"chet_target_critic100v8.h5\")\n",
    "\n",
    "\n",
    "with open('rewardlist400v5.txt', 'r') as filehandle:\n",
    "    for line in filehandle:\n",
    "        # remove linebreak which is the last character of the string\n",
    "        currentPlace = line[:-1]\n",
    "\n",
    "        # add item to the list\n",
    "        ep_reward_list.append(currentPlace)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#env.render()\n",
    "#cymj.MjRenderContextOffscreen(self.sim, 0)\n",
    "dateTimeObj = datetime.now()\n",
    "\n",
    "\n",
    "successNUM=0\n",
    "\n",
    "\n",
    "print(\"Time is: \", dateTimeObj)\n",
    "\n",
    "\n",
    "for ep in range(40000):\n",
    "    prev_state = env.reset()\n",
    "    episodic_reward = 0\n",
    "    epochbuffer = Buffer(50, 128)\n",
    "    while True:\n",
    "        tf_prev_state = tf.expand_dims(tf.convert_to_tensor(prev_state['observation']), 0)\n",
    "        \n",
    "        action = policy(tf_prev_state, ou_noise)\n",
    "        # Recieve state and reward from environment.\n",
    "        state, reward, done, info = env.step(action)\n",
    "\n",
    "        buffer.record((prev_state['observation'] ,action, \n",
    "                       reward, state['observation'],state['achieved_goal'],state['desired_goal']))\n",
    "        episodic_reward += reward\n",
    "        epochbuffer.record((prev_state['observation'] ,action, \n",
    "                       reward, state['observation'],state['achieved_goal'],state['desired_goal']))\n",
    "        \n",
    "        # End this episode when `done` is True\n",
    "        if done:\n",
    "            break \n",
    "    if HER_active==True:\n",
    "            tempreward=0   \n",
    "            for t in range(epochbuffer.buffer_counter):\n",
    "                for k in range(4):\n",
    "                        #For \"future\" strategy\n",
    "                        strategyindex = np.random.randint(t,epochbuffer.buffer_counter)\n",
    "                        \n",
    "                        #For \"final\" strategy\n",
    "                        #strategyindex = epochbuffer.buffer_counter-1\n",
    "                        \n",
    "                        #For \"random\" strategy\n",
    "                        #strategyindex = np.random.randint(0,epochbuffer.buffer_counter)\n",
    "\n",
    "                        stateHER = epochbuffer.state_buffer[t]                 \n",
    "                        actionHER = epochbuffer.action_buffer[t]\n",
    "                        next_stateHER = epochbuffer.next_state_buffer[t]\n",
    "                        achieved_goalHER = epochbuffer.achieved_goal_buffer[t]\n",
    "                        \n",
    "                        goalHER = epochbuffer.achieved_goal_buffer[strategyindex]\n",
    "                        \n",
    "                        rewardHER=env.compute_reward(achieved_goalHER, goalHER, info)\n",
    "                        tempreward+=rewardHER\n",
    "                        buffer.record((stateHER, actionHER, \n",
    "                                         rewardHER, next_stateHER, achieved_goalHER, goalHER))\n",
    "                           \n",
    "    del epochbuffer  \n",
    "    buffer.learn()    \n",
    "    update_target(tau)    \n",
    "    prev_state = state    \n",
    "    if episodic_reward>-50: \n",
    "        successNUM+=1\n",
    "    ep_reward_list.append(episodic_reward)\n",
    "\n",
    "    # Mean of last 40 episodes\n",
    "    #avg_reward = np.mean(ep_reward_list[-40:])\n",
    "    if ep % 100 ==0:\n",
    "        print(\"Episode * {} *  HER Reward: {} *  Ep Reward: {} *  Accuracy: {}\".format(\n",
    "            ep,tempreward, episodic_reward, successNUM/100 ))\n",
    "        successNUM=0\n",
    "    #print(\"buffersize= \",buffer.buffer_counter)\n",
    "    #avg_reward_list.append(avg_reward)\n",
    "    \n",
    "dateTimeObj = datetime.now()\n",
    "print(\"Time is: \", dateTimeObj)\n",
    "\n",
    "# Plotting graph\n",
    "# Episodes versus Avg. Rewards\n",
    "plt.plot(ep_reward_list)\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Episodic Reward\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nwith open('rewardlistreachHER.txt', 'w') as filehandle:\\n     for listitem in ep_reward_list:\\n                filehandle.write('%s\\n' % listitem)\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "actor_model.save_weights(\"pushHER_actor.h5\")\n",
    "critic_model.save_weights(\"pushHER_critic.h5\")\n",
    "\n",
    "target_actor.save_weights(\"pushHER_target_actor.h5\")\n",
    "target_critic.save_weights(\"pushHER_target_critic.h5\")\n",
    "\n",
    "with open('rewardlistpushHER.txt', 'w') as filehandle:\n",
    "    for listitem in ep_reward_list:\n",
    "          filehandle.write('%s\\n' % listitem)\n",
    "                \n",
    "          \n",
    "actor_model.load_weights(\"pushHER_actor40K.h5\")\n",
    "critic_model.load_weights(\"pushHER_critic40K.h5\")\n",
    "\n",
    "target_actor.load_weights(\"pushHER_target_actor40K.h5\")\n",
    "target_critic.load_weights(\"pushHER_target_critic40K.h5\")\n",
    "\"\"\"  \n",
    "\n",
    "actor_model.load_weights(\"reachHER_actor.h5\")\n",
    "critic_model.load_weights(\"reachHER_critic.h5\")\n",
    "\n",
    "target_actor.load_weights(\"reachHER_target_actor.h5\")\n",
    "target_critic.load_weights(\"reachHER_target_critic.h5\")\n",
    "\"\"\"\n",
    "with open('rewardlistreachHER.txt', 'w') as filehandle:\n",
    "     for listitem in ep_reward_list:\n",
    "                filehandle.write('%s\\n' % listitem)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-75580678cbed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# just update the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mFigureCanvasBase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2089\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2090\u001b[0m                     \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2091\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m   2092\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2093\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m             \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m             \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mRendererAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m             \u001b[0;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;31m# don't forget to call the superclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1707\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1709\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2647\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2649\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtick\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mticks_to_draw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1208\u001b[0;31m             \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m         \u001b[0;31m# scale up the axis label box to also find the neighbors, not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    295\u001b[0m         for artist in [self.gridline, self.tick1line, self.tick2line,\n\u001b[1;32m    296\u001b[0m                        self.label1, self.label2]:\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    716\u001b[0m                     textrenderer.draw_text(gc, x, y, clean_line,\n\u001b[1;32m    717\u001b[0m                                            \u001b[0mtextobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fontproperties\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                                            ismath=ismath, mtext=mtext)\n\u001b[0m\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw_text\u001b[0;34m(self, gc, x, y, s, prop, angle, ismath, mtext)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;31m# We pass '0' for angle here, since it will be rotated (in raster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;31m# space) in the following call to draw_text_image).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_glyphs_to_bitmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mantialiased\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text.antialiased'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m64.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#actor_model.load_weights(\"chet_actor140v5.h5\")\n",
    "#critic_model.load_weights(\"chet_critic140v5.h5\")\n",
    "\n",
    "#target_actor.load_weights(\"chet_target_actor140v5.h5\")\n",
    "#target_critic.load_weights(\"chet_target_critic140v5.h5\")\n",
    "\n",
    "\n",
    "img = plt.imshow(env.render(mode='rgb_array')) # only call this once\n",
    "success=0\n",
    "for j in range(10):\n",
    "    env.reset()\n",
    "    \n",
    "    for j in range(50):\n",
    "        \n",
    "        \n",
    "        img.set_data(env.render(mode='rgb_array')) # just update the data\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "        \n",
    "        \n",
    "        #env.render()\n",
    "        action = env.action_space.sample()\n",
    "    #env.step(action)  #investigate \n",
    "        state, reward, done, info = env.step(action)\n",
    "        if reward==0:\n",
    "            #print(\"reached target at timestep\",i)\n",
    "            success+=1\n",
    "            break\n",
    "\n",
    "print(\"sucesses=\",success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
