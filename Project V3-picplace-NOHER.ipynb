{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "\n",
    "## Scott Scheraga  7/24/2020\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker\n",
      "Worker\n",
      "Worker\n",
      "Worker\n",
      "Worker\n",
      "Worker\n",
      "Worker\n",
      "Worker\n",
      "Worker\n",
      "Worker\n",
      "Worker\n",
      "Worker\n",
      "Worker\n",
      "Worker\n",
      "Worker\n",
      "Worker"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WorkerWorkerWorker\n",
      "\n",
      "\n",
      "Worker\n"
     ]
    }
   ],
   "source": [
    "#Code is largely built off of https://keras.io/examples/rl/ddpg_pendulum/\n",
    "#HER code is inspired by pybullet code at https://github.com/buntyke/her/blob/master/ddpg_her.py\n",
    "\n",
    "#from gym.envs.registration import registry, make, spec, register\n",
    "#python -m pybullet_envs.examples.enjoy_TF_HalfCheetahBulletEnv_v0_2017may\n",
    "\n",
    "\n",
    "import gym\n",
    "import pybullet_envs\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gym import wrappers\n",
    "from IPython import display\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "import math \n",
    "\n",
    "import os\n",
    "import gym\n",
    "from gym import utils\n",
    "from gym.envs import mujoco\n",
    "import mujoco_py\n",
    "import cv2\n",
    "from gym.envs.robotics import fetch_env\n",
    "import threading\n",
    "threading.activeCount()\n",
    "\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "def worker():\n",
    "    \"\"\"worker function\"\"\"\n",
    "    print ('Worker')\n",
    "    return\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    jobs = []\n",
    "    for i in range(20):\n",
    "        p = multiprocessing.Process(target=worker)\n",
    "        jobs.append(p)\n",
    "        p.start()\n",
    "        \n",
    "threading.activeCount()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from gym import utils\n",
    "from gym.envs.robotics import fetch_env\n",
    "\n",
    "\n",
    "# Ensure we get the path separator correct on windows\n",
    "MODEL_XML_PATH = os.path.join('fetch', 'pick_and_place.xml')\n",
    "\n",
    "\n",
    "class FetchPickAndPlaceEnv(fetch_env.FetchEnv, utils.EzPickle):\n",
    "    def __init__(self, reward_type='sparse'):\n",
    "        initial_qpos = {\n",
    "            'robot0:slide0': 0.405,\n",
    "            'robot0:slide1': 0.48,\n",
    "            'robot0:slide2': 0.0,\n",
    "            'object0:joint': [1.25, 0.53, 0.4, 1., 0., 0., 0.],\n",
    "        }\n",
    "        fetch_env.FetchEnv.__init__(\n",
    "            self, MODEL_XML_PATH, has_object=True, block_gripper=False, n_substeps=20,\n",
    "            gripper_extra_height=0.2, target_in_the_air=True, target_offset=0.0,\n",
    "            obj_range=0.15, target_range=0.15, distance_threshold=0.05,\n",
    "            initial_qpos=initial_qpos, reward_type=reward_type)\n",
    "        utils.EzPickle.__init__(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs space\n",
      "Dict(achieved_goal:Box(3,), desired_goal:Box(3,), observation:Box(25,))\n",
      "OrderedDict([('achieved_goal', array([ 0.45334107,  0.02081207, -0.8259729 ], dtype=float32)), ('desired_goal', array([-0.7854697 ,  0.14690578, -0.84708405], dtype=float32)), ('observation', array([-1.4839239 , -3.0708714 ,  0.78428715, -1.1605912 ,  0.39489165,\n",
      "        1.1694113 ,  1.5057251 , -0.14418621,  0.2735341 , -0.88597864,\n",
      "       -0.45269164,  1.4047276 ,  1.2230396 , -0.1695792 , -0.52591366,\n",
      "       -1.0809313 , -0.90799475,  0.6896055 , -2.5457828 , -0.17288089,\n",
      "       -0.5782125 , -0.0888069 ,  1.2917271 , -1.9016705 , -0.9111972 ],\n",
      "      dtype=float32))])\n",
      " \n",
      " \n",
      "Action space\n",
      "Box(4,)\n",
      "[ 0.41578355  0.30104208  0.6963807  -0.869791  ]\n",
      "numgoals= 3\n",
      " \n",
      " \n",
      "Size of State Space ->  25\n",
      "Size of Action Space ->  4\n",
      "Max Value of Action ->  1.0\n",
      "Min Value of Action ->  -1.0\n",
      " \n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#env = gym.make('Pendulum-v0')\n",
    "#env = gym.make('CartPole-v1')\n",
    "#env = gym.make('HalfCheetahBulletEnv-v0')\n",
    "\n",
    "\n",
    "env = gym.make('FetchPickAndPlace-v1')\n",
    "\n",
    "\n",
    "#env = gym.make('FetchPush-v1')\n",
    "#env = gym.make('FetchReach-v1')\n",
    "\n",
    "#env = gym.make('Reacher-v2')\n",
    "\n",
    "#Env information at:\n",
    "# https://medium.com/@Amritpal001/intro-to-robotics-in-openai-fetch-reach-env-automating-robotics-with-reinforcement-learning-part-2b7452f3a5e9\n",
    "\n",
    "print(\"Obs space\")\n",
    "print(env.observation_space) #.shape\n",
    "print(env.observation_space.sample())\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\"Action space\")\n",
    "print(env.action_space) #.shape\n",
    "print(env.action_space.sample())\n",
    "num_states = env.observation_space['observation'].shape[0]\n",
    "num_goals = env.observation_space['achieved_goal'].shape[0]\n",
    "print(\"numgoals=\",num_goals)\n",
    "\n",
    "#num_states = env.observation_space.shape[0]\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "#num_states=25\n",
    "print(\"Size of State Space ->  {}\".format(num_states))\n",
    "num_actions = env.action_space.shape[0]\n",
    "print(\"Size of Action Space ->  {}\".format(num_actions))\n",
    "\n",
    "upper_bound = env.action_space.high[0]\n",
    "lower_bound = env.action_space.low[0]\n",
    "\n",
    "print(\"Max Value of Action ->  {}\".format(upper_bound))\n",
    "print(\"Min Value of Action ->  {}\".format(lower_bound))\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "#print(\"initial_state\")\n",
    "#print(env.initial_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom gym import utils\\nfrom gym.envs.robotics import fetch_env\\n\\n\\n# Ensure we get the path separator correct on windows\\nMODEL_XML_PATH = os.path.join('fetch', 'reach.xml')\\n\\n\\nclass FetchReachEnv(fetch_env.FetchEnv, utils.EzPickle):\\n    def __init__(self, reward_type='sparse'):\\n        initial_qpos = {\\n            'robot0:slide0': 0.4049,\\n            'robot0:slide1': 0.48,\\n            'robot0:slide2': 0.0,\\n        }\\n        fetch_env.FetchEnv.__init__(\\n            self, MODEL_XML_PATH, has_object=False, block_gripper=True, n_substeps=20,\\n            gripper_extra_height=0.2, target_in_the_air=True, target_offset=0.0,\\n            obj_range=0.15, target_range=0.15, distance_threshold=0.05,\\n            initial_qpos=initial_qpos, reward_type=reward_type)\\n        utils.EzPickle.__init__(self)\\n        \\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fetch reach definition\n",
    "#https://github.com/openai/gym/blob/master/gym/envs/robotics/fetch/reach.py\n",
    "\"\"\"\n",
    "from gym import utils\n",
    "from gym.envs.robotics import fetch_env\n",
    "\n",
    "\n",
    "# Ensure we get the path separator correct on windows\n",
    "MODEL_XML_PATH = os.path.join('fetch', 'reach.xml')\n",
    "\n",
    "\n",
    "class FetchReachEnv(fetch_env.FetchEnv, utils.EzPickle):\n",
    "    def __init__(self, reward_type='sparse'):\n",
    "        initial_qpos = {\n",
    "            'robot0:slide0': 0.4049,\n",
    "            'robot0:slide1': 0.48,\n",
    "            'robot0:slide2': 0.0,\n",
    "        }\n",
    "        fetch_env.FetchEnv.__init__(\n",
    "            self, MODEL_XML_PATH, has_object=False, block_gripper=True, n_substeps=20,\n",
    "            gripper_extra_height=0.2, target_in_the_air=True, target_offset=0.0,\n",
    "            obj_range=0.15, target_range=0.15, distance_threshold=0.05,\n",
    "            initial_qpos=initial_qpos, reward_type=reward_type)\n",
    "        utils.EzPickle.__init__(self)\n",
    "        \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUActionNoise:\n",
    "    def __init__(self, mean, std_deviation, theta=0.15, dt=1e-2, x_initial=None):\n",
    "        self.theta = theta\n",
    "        self.mean = mean\n",
    "        self.std_dev = std_deviation\n",
    "        self.dt = dt\n",
    "        self.x_initial = x_initial\n",
    "        self.reset()\n",
    "\n",
    "    def __call__(self):\n",
    "        # Formula taken from https://www.wikipedia.org/wiki/Ornstein-Uhlenbeck_process.\n",
    "        x = (\n",
    "            self.x_prev\n",
    "            + self.theta * (self.mean - self.x_prev) * self.dt\n",
    "            + self.std_dev * np.sqrt(self.dt) * np.random.normal(size=self.mean.shape)\n",
    "        )\n",
    "        # Store x into x_prev\n",
    "        # Makes next noise dependent on current one\n",
    "        self.x_prev = x\n",
    "        return x\n",
    "\n",
    "    def reset(self):\n",
    "        if self.x_initial is not None:\n",
    "            self.x_prev = self.x_initial\n",
    "        else:\n",
    "            self.x_prev = np.zeros_like(self.mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buffer:\n",
    "    def __init__(self, buffer_capacity=100000, batch_size=256):\n",
    "    \n",
    "        # Number of \"experiences\" to store at max\n",
    "        self.buffer_capacity = buffer_capacity\n",
    "        # Num of tuples to train on.\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Its tells us num of times record() was called.\n",
    "        self.buffer_counter = 0\n",
    "\n",
    "        # Instead of list of tuples as the exp.replay concept go\n",
    "        # We use different np.arrays for each tuple element\n",
    "        self.state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        self.action_buffer = np.zeros((self.buffer_capacity, num_actions))\n",
    "        self.reward_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.next_state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        self.achieved_goal_buffer = np.zeros((self.buffer_capacity, num_goals))\n",
    "        self.goal_buffer = np.zeros((self.buffer_capacity, num_goals)) \n",
    "\n",
    "    # Takes (s,a,r,s') obervation tuple as input\n",
    "    def record(self, obs_tuple):\n",
    "        # Set index to zero if buffer_capacity is exceeded,\n",
    "        # replacing old records\n",
    "        index = self.buffer_counter % self.buffer_capacity\n",
    "\n",
    "        self.state_buffer[index] = obs_tuple[0]\n",
    "        self.action_buffer[index] = obs_tuple[1]\n",
    "        self.reward_buffer[index] = obs_tuple[2]\n",
    "        self.next_state_buffer[index] = obs_tuple[3]\n",
    "        self.achieved_goal_buffer[index] = obs_tuple[4]\n",
    "        self.goal_buffer[index] = obs_tuple[5]\n",
    "        \n",
    "        \n",
    "        if self.buffer_counter<self.buffer_capacity:\n",
    "            self.buffer_counter += 1\n",
    "            \n",
    "\n",
    "    # We compute the loss and update parameters\n",
    "    def learn(self):\n",
    "        # Get sampling range\n",
    "        record_range = min(self.buffer_counter, self.buffer_capacity)\n",
    "        # Randomly sample indices\n",
    "        batch_indices = np.random.choice(record_range, self.batch_size)\n",
    "\n",
    "        # Convert to tensors\n",
    "        state_batch = tf.convert_to_tensor(self.state_buffer[batch_indices])\n",
    "        action_batch = tf.convert_to_tensor(self.action_buffer[batch_indices])\n",
    "        reward_batch = tf.convert_to_tensor(self.reward_buffer[batch_indices])\n",
    "        reward_batch = tf.cast(reward_batch, dtype=tf.float32)\n",
    "        next_state_batch = tf.convert_to_tensor(self.next_state_buffer[batch_indices])\n",
    "        achieved_goal_batch = tf.convert_to_tensor(self.achieved_goal_buffer[batch_indices])\n",
    "        goal_batch = tf.convert_to_tensor(self.goal_buffer[batch_indices])\n",
    "\n",
    "        # Training and updating Actor & Critic networks.\n",
    "        # See Pseudo Code.\n",
    "        with tf.GradientTape() as tape:\n",
    "            target_actions = target_actor(next_state_batch)\n",
    "            y = reward_batch + gamma * target_critic([next_state_batch, target_actions])\n",
    "            critic_value = critic_model([state_batch, action_batch])\n",
    "            critic_loss = tf.math.reduce_mean(tf.math.square(y - critic_value))\n",
    "\n",
    "        critic_grad = tape.gradient(critic_loss, critic_model.trainable_variables)\n",
    "        critic_optimizer.apply_gradients(\n",
    "            zip(critic_grad, critic_model.trainable_variables)\n",
    "        )\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            actions = actor_model(state_batch)\n",
    "            critic_value = critic_model([state_batch, actions])\n",
    "            # Used `-value` as we want to maximize the value given\n",
    "            # by the critic for our actions\n",
    "            actor_loss = -tf.math.reduce_mean(critic_value)\n",
    "\n",
    "        actor_grad = tape.gradient(actor_loss, actor_model.trainable_variables)\n",
    "        actor_optimizer.apply_gradients(\n",
    "            zip(actor_grad, actor_model.trainable_variables)\n",
    "        )\n",
    "\n",
    "\n",
    "# This update target parameters slowly\n",
    "# Based on rate `tau`, which is much less than one.\n",
    "def update_target(tau):\n",
    "    new_weights = []\n",
    "    target_variables = target_critic.weights\n",
    "    for i, variable in enumerate(critic_model.weights):\n",
    "        new_weights.append(variable * tau + target_variables[i] * (1 - tau))\n",
    "\n",
    "    target_critic.set_weights(new_weights)\n",
    "\n",
    "    new_weights = []\n",
    "    target_variables = target_actor.weights\n",
    "    for i, variable in enumerate(actor_model.weights):\n",
    "        new_weights.append(variable * tau + target_variables[i] * (1 - tau))\n",
    "\n",
    "    target_actor.set_weights(new_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "layersize=400\n",
    "\n",
    "def get_actor():  #makes actor network\n",
    "    # Initialize weights between -3e-3 and 3-e3\n",
    "    last_init = tf.random_uniform_initializer(minval=-0.003, maxval=0.003)\n",
    "\n",
    "    inputs = layers.Input(shape=(num_states,))\n",
    "    out = layers.Dense(layersize, activation=\"relu\")(inputs)\n",
    "    out = layers.BatchNormalization()(out)\n",
    "    out = layers.Dense(layersize, activation=\"relu\")(out)\n",
    "    out = layers.BatchNormalization()(out)\n",
    "    outputs = layers.Dense(num_actions, activation=\"tanh\", kernel_initializer=last_init)(out)\n",
    "    # Our upper bound is 2.0 for Pendulum.\n",
    "    outputs = outputs * upper_bound\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model\n",
    " \n",
    "def get_critic():\n",
    "    # State as input\n",
    "    state_input = layers.Input(shape=(num_states))\n",
    "    #state_out = layers.Dense(16, activation=\"relu\")(state_input)#Changed from 16 to 512 in V5\n",
    "    #state_out = layers.BatchNormalization()(state_out)\n",
    "    #state_out = layers.Dense(32, activation=\"relu\")(state_out)#Changed from 32 to 512 in V5\n",
    "    #state_out = layers.BatchNormalization()(state_out) \n",
    "\n",
    "    # Action as input\n",
    "    action_input = layers.Input(shape=(num_actions))\n",
    "    #action_out = layers.Dense(32, activation=\"relu\")(action_input)  #Changed from 32 to 512 in V5\n",
    "    #action_out = layers.BatchNormalization()(action_out)#Changed from 32 to 512 in V5\n",
    "\n",
    " \n",
    "    # Both are passed through seperate layer before concatenating\n",
    "    #concat = layers.Concatenate()([state_out, action_out])\n",
    "    concat = layers.Concatenate()([state_input, action_input])\n",
    "\n",
    "    out = layers.Dense(layersize, activation=\"relu\")(concat)\n",
    "    out = layers.BatchNormalization()(out)\n",
    "    out = layers.Dense(layersize, activation=\"relu\")(out)\n",
    "    out = layers.BatchNormalization()(out)\n",
    "    outputs = layers.Dense(1)(out)\n",
    "\n",
    "    # Outputs single value for give state-action\n",
    "    model = tf.keras.Model([state_input, action_input], outputs)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(state, noise_object):\n",
    "    sampled_actions = tf.squeeze(actor_model(state))\n",
    "    noise = noise_object()\n",
    "    # Adding noise to action\n",
    "    sampled_actions = sampled_actions.numpy() + noise\n",
    "\n",
    "    # We make sure action is within bounds\n",
    "    legal_action = np.clip(sampled_actions, lower_bound, upper_bound)\n",
    "\n",
    "    return np.squeeze(legal_action)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "std_dev = 0.2\n",
    "ou_noise = OUActionNoise(mean=np.zeros(1), std_deviation=float(std_dev) * np.ones(1))\n",
    "\n",
    "#actor_model = get_actor()\n",
    "#critic_model = get_critic()\n",
    "\n",
    "#target_actor = get_actor()\n",
    "#target_critic = get_critic()\n",
    "#print(actor_model.summary() )\n",
    "#critic_model.summary() \n",
    "\n",
    "# Making the weights equal initially\n",
    "\n",
    "\n",
    "# Learning rate for actor-critic models\n",
    "critic_lr = 0.001  #originally .002\n",
    "actor_lr = 0.001  #originally .001\n",
    "\n",
    "\n",
    "#total_episodes = 100\n",
    "# Discount factor for future rewards\n",
    "gamma = 0.99\n",
    "# Used to update target networks\n",
    "tau = 0.01\n",
    "\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time is:  2020-07-24 13:40:22.572067\n",
      "Episode * 0 *  HER Reward: 0.0 *  Episodic Reward: -50.0\n",
      "Episode * 1 *  HER Reward: 0.0 *  Episodic Reward: 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ac1a77f79553>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mepochbuffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0mupdate_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtau\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mprev_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-e512d35c64f5>\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mactor_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcritic_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mactor_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactor_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactor_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         actor_optimizer.apply_gradients(\n\u001b[1;32m     77\u001b[0m             \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactor_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactor_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gradient_tape/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/tensorflow/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_ReluGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegisterGradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_ReluGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_nn_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mrelu_grad\u001b[0;34m(gradients, features, name)\u001b[0m\n\u001b[1;32m  10533\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m  10534\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ReluGrad\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10535\u001b[0;31m         tld.op_callbacks, gradients, features)\n\u001b[0m\u001b[1;32m  10536\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10537\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# To store reward history of each episode\n",
    "\n",
    "ep_reward_list = []\n",
    "buffersize=100000\n",
    "buffer = Buffer(buffersize, 128)  \n",
    "actor_model = get_actor()\n",
    "critic_model = get_critic()\n",
    "\n",
    "\n",
    "target_actor = get_actor()\n",
    "target_critic = get_critic()\n",
    "target_actor.set_weights(actor_model.get_weights())\n",
    "target_critic.set_weights(critic_model.get_weights())\n",
    "critic_optimizer = tf.keras.optimizers.Adam(critic_lr)\n",
    "actor_optimizer = tf.keras.optimizers.Adam(actor_lr)\n",
    "\"\"\"\"\"\"\n",
    "\n",
    "HER_active=True\n",
    "K=4 #K is the ratio of HER buffer length to the regular buffer length\n",
    "\n",
    "\"\"\"\n",
    "actor_model.load_weights(\"chet_actor100v8.h5\")\n",
    "critic_model.load_weights(\"chet_critic100v8.h5\")\n",
    "\n",
    "target_actor.load_weights(\"chet_target_actor100v8.h5\")\n",
    "target_critic.load_weights(\"chet_target_critic100v8.h5\")\n",
    "\n",
    "\n",
    "with open('rewardlist400v5.txt', 'r') as filehandle:\n",
    "    for line in filehandle:\n",
    "        # remove linebreak which is the last character of the string\n",
    "        currentPlace = line[:-1]\n",
    "\n",
    "        # add item to the list\n",
    "        ep_reward_list.append(currentPlace)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#env.render()\n",
    "#cymj.MjRenderContextOffscreen(self.sim, 0)\n",
    "dateTimeObj = datetime.now()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Time is: \", dateTimeObj)\n",
    "\n",
    "\n",
    "for ep in range(16941+40000):\n",
    "    \"\"\"\n",
    "    if ep % 1000 ==0: \n",
    "        actor_model.save_weights(\"picplace_actor.h5\")\n",
    "        critic_model.save_weights(\"picplace_critic.h5\")\n",
    "\n",
    "        target_actor.save_weights(\"picplace_target_actor.h5\")\n",
    "        target_critic.save_weights(\"picplace_target_critic.h5\")\n",
    "\n",
    "        with open('rewardlistpicplace.txt', 'w') as filehandle:\n",
    "            for listitem in ep_reward_list:\n",
    "                filehandle.write('%s\\n' % listitem)\n",
    "                \n",
    "    \"\"\"            \n",
    "    prev_state = env.reset()\n",
    "    \n",
    "    episodic_reward = 0\n",
    "    #if HER_active==True:\n",
    "    #epochbuffer = Buffer(50, 128)\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        #achievedcounter=0\n",
    "        #env.render()\n",
    "\n",
    "        tf_prev_state = tf.expand_dims(tf.convert_to_tensor(prev_state['observation']), 0)\n",
    "        #tf_prev_state = tf.expand_dims(tf.convert_to_tensor(prev_state), 0)\n",
    "        \n",
    "        action = policy(tf_prev_state, ou_noise)\n",
    "        # Recieve state and reward from environment.\n",
    "        state, reward, done, info = env.step(action)\n",
    "\n",
    "        #desired_goal\n",
    "        #achieved_goal\n",
    "        buffer.record((prev_state['observation'] ,action, \n",
    "                       reward, state['observation'],state['achieved_goal'],state['desired_goal']))\n",
    "        \n",
    "        episodic_reward += reward\n",
    "        \n",
    "        \n",
    "        epochbuffer.record((prev_state['observation'] ,action, \n",
    "                       reward, state['observation'],state['achieved_goal'],state['desired_goal']))\n",
    "        #buffer.record((prev_state, action, reward, state))\n",
    "  \n",
    "        \n",
    "        # End this episode when `done` is True\n",
    "        \n",
    "        if done:\n",
    "            break \n",
    "    \"\"\"       \n",
    "    if HER_active==True:\n",
    "            #print(\"epochbuffer.buffer_counter=\",epochbuffer.buffer_counter)\n",
    "            tempreward=0\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            for t in range(epochbuffer.buffer_counter):\n",
    "                \n",
    "                for k in range(4):\n",
    "                        #For \"future\" strategy\n",
    "                        strategyindex = np.random.randint(t,epochbuffer.buffer_counter)\n",
    "                        \n",
    "                        #For \"final\" strategy\n",
    "                        #strategyindex = epochbuffer.buffer_counter-1\n",
    "                        \n",
    "                        #For \"random\" strategy\n",
    "                        #strategyindex = np.random.randint(0,epochbuffer.buffer_counter)\n",
    "                        \n",
    "\n",
    "                        stateHER = epochbuffer.state_buffer[t]                 \n",
    "                        actionHER = epochbuffer.action_buffer[t]\n",
    "                        next_stateHER = epochbuffer.next_state_buffer[t]\n",
    "                        achieved_goalHER = epochbuffer.achieved_goal_buffer[t]\n",
    "                        \n",
    "                        goalHER = epochbuffer.achieved_goal_buffer[strategyindex]\n",
    "                        \n",
    "                        rewardHER=env.compute_reward(achieved_goalHER, goalHER, info)\n",
    "                        tempreward+=rewardHER\n",
    "\n",
    "                                    # add new experience to her\n",
    "                        buffer.record((stateHER, actionHER, \n",
    "                                         rewardHER, next_stateHER, achieved_goalHER, goalHER))\n",
    "    \"\"\"                    \n",
    "                        \n",
    "            #print(\"HERreward=\",tempreward)            \n",
    "            #HERbuffer.learn()\n",
    "            #del HERbuffer  \n",
    "    #del epochbuffer  \n",
    "        \n",
    "    buffer.learn()    \n",
    "    update_target(tau)    \n",
    "    prev_state = state    \n",
    "        \n",
    "    ep_reward_list.append(episodic_reward)\n",
    "\n",
    "    # Mean of last 40 episodes\n",
    "    #avg_reward = np.mean(ep_reward_list[-40:])\n",
    "    \n",
    "    print(\"Episode * {} *  HER Reward: {} *  Episodic Reward: {}\".format(ep,tempreward, episodic_reward ))\n",
    "    #print(\"buffersize= \",buffer.buffer_counter)\n",
    "    #avg_reward_list.append(avg_reward)\n",
    "    \n",
    "dateTimeObj = datetime.now()\n",
    "print(\"Time is: \", dateTimeObj)\n",
    "\n",
    "# Plotting graph\n",
    "# Episodes versus Avg. Rewards\n",
    "plt.plot(ep_reward_list)\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Avg. Episodic Reward\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "actor_model.save_weights(\"picplace_actor.h5\")\n",
    "critic_model.save_weights(\"picplace_critic.h5\")\n",
    "\n",
    "target_actor.save_weights(\"picplace_target_actor.h5\")\n",
    "target_critic.save_weights(\"picplace_target_critic.h5\")\n",
    "\n",
    "with open('rewardlistpicplace.txt', 'w') as filehandle:\n",
    "     for listitem in ep_reward_list:\n",
    "                filehandle.write('%s\\n' % listitem)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.plot(ep_reward_list)\n",
    "#plt.xlabel(\"Episode\")\n",
    "#plt.ylabel(\"Avg. Episodic Reward\")\n",
    "#plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-948a4a8f79ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# just update the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mFigureCanvasBase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2067\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2068\u001b[0m                     bbox_inches = self.figure.get_tightbbox(renderer,\n\u001b[0;32m-> 2069\u001b[0;31m                             bbox_extra_artists=bbox_artists)\n\u001b[0m\u001b[1;32m   2070\u001b[0m                     \u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pad_inches\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mpad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer, bbox_extra_artists)\u001b[0m\n\u001b[1;32m   2365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2366\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2367\u001b[0;31m             \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2368\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2369\u001b[0m                 \u001b[0mbb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1166\u001b[0m         \u001b[0;31m# go back to just this axis's tick labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m         ticklabelBoxes, ticklabelBoxes2 = self._get_tick_bboxes(\n\u001b[0;32m-> 1168\u001b[0;31m                     ticks_to_draw, renderer)\n\u001b[0m\u001b[1;32m   1169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_offset_text_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticklabelBoxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mticklabelBoxes2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick_bboxes\u001b[0;34m(self, ticks, renderer)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;34m\"\"\"Return lists of bboxes for ticks' label1's and label2's.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         return ([tick.label1.get_window_extent(renderer)\n\u001b[0;32m-> 1150\u001b[0;31m                  for tick in ticks if tick.label1.get_visible()],\n\u001b[0m\u001b[1;32m   1151\u001b[0m                 [tick.label2.get_window_extent(renderer)\n\u001b[1;32m   1152\u001b[0m                  for tick in ticks if tick.label2.get_visible()])\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;34m\"\"\"Return lists of bboxes for ticks' label1's and label2's.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         return ([tick.label1.get_window_extent(renderer)\n\u001b[0;32m-> 1150\u001b[0;31m                  for tick in ticks if tick.label1.get_visible()],\n\u001b[0m\u001b[1;32m   1151\u001b[0m                 [tick.label2.get_window_extent(renderer)\n\u001b[1;32m   1152\u001b[0m                  for tick in ticks if tick.label2.get_visible()])\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mget_window_extent\u001b[0;34m(self, renderer, dpi)\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unitless_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m         \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdpi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdpi_orig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36mtranslated\u001b[0;34m(self, tx, ty)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranslated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0;34m\"\"\"Construct a `Bbox` by translating this one by *tx* and *ty*.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mBbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_points\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcorners\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/csci-7000-rl/lib/python3.7/site-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, points, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m                              '\"[[x0, y0], [x1, y1]]\".')\n\u001b[1;32m    744\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_minpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ignore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;31m# it is helpful in some contexts to know if the bbox is a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "actor_model.load_weights(\"picplace_actor.h5\")\n",
    "critic_model.load_weights(\"picplace_critic.h5\")\n",
    "\n",
    "target_actor.load_weights(\"picplace_target_actor.h5\")\n",
    "target_critic.load_weights(\"picplace_target_critic.h5\")\n",
    "\n",
    "\n",
    "img = plt.imshow(env.render(mode='rgb_array')) # only call this once\n",
    "success=0\n",
    "for j in range(10):\n",
    "    env.reset()\n",
    "    for j in range(50):\n",
    "        img.set_data(env.render(mode='rgb_array')) # just update the data\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "        action = env.action_space.sample()\n",
    "    #env.step(action)  #investigate \n",
    "        state, reward, done, info = env.step(action)\n",
    "        if reward==0:\n",
    "            print(\"reached target at timestep\",i)\n",
    "            success+=1\n",
    "            break\n",
    "print(\"sucesses=\",success)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "actor_model.load_weights(\"chet_actor200v7.h5\")\n",
    "critic_model.load_weights(\"chet_critic200v7.h5\")\n",
    "\n",
    "target_actor.load_weights(\"chet_target_actor200v87.h5\")\n",
    "target_critic.load_weights(\"chet_target_critic200v7.h5\")\n",
    "\n",
    "with open('rewardlist200v8.txt', 'w') as filehandle:\n",
    "    for listitem in ep_reward_list:\n",
    "        filehandle.write('%s\\n' % listitem)\n",
    "\"\"\"      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
